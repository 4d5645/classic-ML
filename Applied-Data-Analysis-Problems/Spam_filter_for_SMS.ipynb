{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Spam filter for SMS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcnhrZkpGxHkR6WS14xQjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4d5645/AppliedDataAnalysisProblems_MIPT/blob/main/Spam_filter_for_SMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from __future__ import division, print_function\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "TINC62iNjViT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Loading the dataset"
      ],
      "metadata": {
        "id": "3ed4AUlbq9p3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmo6kn93iJ6K",
        "outputId": "a45ad6ff-a051-491d-a911-6b0041260af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "with open('/content/gdrive/MyDrive/Colab Notebooks/MIPT/smsspamcollection/SMSSpamCollection.txt', 'r') as f:\n",
        "    data = f.read().splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's prepare two lists for further work: a list of texts in the order they appear in the dataset and a list of class labels corresponding to them. We use 1 for spam and 0 for \"not spam\" as the class label."
      ],
      "metadata": {
        "id": "hRlsFpqerJZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HAXYDnBK6KUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [data[i].split('\\t')[0] for i in range(len(data))]\n",
        "content = [data[i].split('\\t')[1] for i in range(len(data))]\n",
        "# print(labels)\n",
        "# print(content)"
      ],
      "metadata": {
        "id": "_e4TdBoolkZc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_labels = np.zeros(len(labels))\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == 'ham':\n",
        "    binary_labels[i] = 0\n",
        "  else:\n",
        "    binary_labels[i] = 1"
      ],
      "metadata": {
        "id": "GIlU3YO0nLdF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X= vectorizer.fit_transform(content)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkDkWbqmBnD7",
        "outputId": "47fab34d-b13b-4182-d4ba-7b5d2ef2a56e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5574, 8713)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([('count_vect', CountVectorizer()), ('log_reg', LogisticRegression())])"
      ],
      "metadata": {
        "id": "8-lymB5s63d-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = cross_val_score(pipeline, content, binary_labels, scoring='f1', cv=10).mean()\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2DbkUqJ66kR",
        "outputId": "6392950b-f184-40c2-809e-0cc2b01774a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9311052112181922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sms = [ \"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
        "       \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
        "       \"Have you visited the last lecture on physics?\",\n",
        "       \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
        "       \"Only 99$\",\n",
        "       ]"
      ],
      "metadata": {
        "id": "JsgC6-xB68z4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(content, binary_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvk592t37ndH",
        "outputId": "e5f3b9e5-3975-4212-ef81-2a4a13840638"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
              "                ('log_reg', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pipeline.predict(sms)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aanJhJM27sZx",
        "outputId": "3e2502de-29b7-4a6b-d64e-4d69a0602237"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams = [(2,2), (3,3), (1,3)]\n",
        "\n",
        "scores = []\n",
        "for ngram in ngrams:\n",
        "    pipeline = Pipeline([('count_vect', CountVectorizer(ngram_range=ngram)), ('log_reg', LogisticRegression())])\n",
        "    score = cross_val_score(pipeline, content, binary_labels, scoring='f1', cv=10).mean()\n",
        "    scores.append(score)\n",
        "    print('Ngram_range: ', ngram)\n",
        "    print('Cross-val-score f1: %.4f\\n' % score)"
      ],
      "metadata": {
        "id": "_K_16NPP73Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021992d1-678d-4ce9-b608-99434a08101b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngram_range:  (2, 2)\n",
            "Cross-val-score f1: 0.8168\n",
            "\n",
            "Ngram_range:  (3, 3)\n",
            "Cross-val-score f1: 0.7250\n",
            "\n",
            "Ngram_range:  (1, 3)\n",
            "Cross-val-score f1: 0.9223\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for ngram in ngrams:\n",
        "    X_counts = CountVectorizer(ngram_range=ngram).fit_transform(content)\n",
        "    mn_nb = MultinomialNB()\n",
        "    score = cross_val_score(mn_nb, X_counts, binary_labels, scoring='f1', cv=10).mean()\n",
        "    scores.append(score)\n",
        "    print('Ngram_range: ', ngram)\n",
        "    print('Cross-val-score f1: %.4f\\n' % score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3dwvn7F-dWN",
        "outputId": "9d42255c-1603-403a-e1bf-0a2a312c64b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngram_range:  (2, 2)\n",
            "Cross-val-score f1: 0.6451\n",
            "\n",
            "Ngram_range:  (3, 3)\n",
            "Cross-val-score f1: 0.3786\n",
            "\n",
            "Ngram_range:  (1, 3)\n",
            "Cross-val-score f1: 0.8878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([('tf_idf', TfidfVectorizer()),\n",
        "                     ('log_reg', LogisticRegression())])\n",
        "score = cross_val_score(pipeline, content, binary_labels, scoring='f1', cv=10).mean()\n",
        "print('Cross-val-score f1: %.4f\\n' % score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf_Hs5Ra-2HF",
        "outputId": "51fb3575-f1c7-4060-8e98-80e0e504369e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-val-score f1: 0.8784\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wvCDwoe4_RYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}